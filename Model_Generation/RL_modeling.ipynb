{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done importing\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.integrate import solve_ivp\n",
    "import synthetic_data\n",
    "# import tensorflow as tf\n",
    "import torch\n",
    "\n",
    "print(\"done importing\")\n",
    "\n",
    "class TrapEnvironment:\n",
    "    def __init__(self, num_traps=20,max_steps=1000):\n",
    "        # Initialize environment parameters\n",
    "        self.num_traps = num_traps\n",
    "        self.n = 25\n",
    "        self.m = 25\n",
    "        self.predator_density = None\n",
    "        self.prey_density = None\n",
    "        self.trap_replacement_rate = 10\n",
    "        self.pts_per_sec = 100\n",
    "        self.len_traj=50\n",
    "        self.current_step = 0\n",
    "        self.max_steps = max_steps\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        # Reset the environment to its initial state (just predator and prey)\n",
    "        # Generate initial predator and prey densities\n",
    "        # default params for initial generation num_traj=200,len_traj=50, pts_per_sec=100, save_loc='../Data/val.npy', prey_range=(1, 5), predator_range=(1, 3)\n",
    "        data_init = synthetic_data.generate().reshape(self.n, self.m, 2, self.pts_per_sec*self.len_traj)\n",
    "        self.prey_density, self.predator_density = data_init[:, :, 0, -1], data_init[:, :, 1, -1]\n",
    "        return self.predator_density, self.prey_density\n",
    "\n",
    "    def step(self, action):\n",
    "        # Take action (place traps) and observe the next state and reward\n",
    "        # Update predator and prey densities based on the action\n",
    "        # Calculate reward based on the change in predator density\n",
    "        # Return next state, reward, and done flag\n",
    "\n",
    "        # Simulate predator dynamics with traps placed at specified locations\n",
    "        # Here, action is a list of trap locations [(i1, j1), (i2, j2), ..., (in, jn)]\n",
    "        y0 = np.zeros((self.n, self.m, 2))\n",
    "        y0[:,:,0] = self.predator_density\n",
    "        prey_data = self.prey_density\n",
    "        for i, j in action:\n",
    "            y0[i,j,1] = 10  # place those traps at each cell\n",
    "        y0 = y0.flatten()\n",
    "\n",
    "        # get impact on predator and prey spread after placement window steps\n",
    "        master_sol = np.ndarray((self.n*self.m*2,self.pts_per_sec))\n",
    "        \n",
    "        for _ in range(self.trap_replacement_rate):\n",
    "            # trap solver, only grab single timestep\n",
    "            sol = solve_ivp(synthetic_data.spatial_dynamics_traps, y0=y0, t_span=[0,1], t_eval=np.linspace(0, 1, self.pts_per_sec), args=(self.n, self.m))\n",
    "            # prey solver y0 creation\n",
    "            y_prey = np.zeros((self.n, self.m, 2))\n",
    "            last_dim = int(self.pts_per_sec)\n",
    "            sol_use = sol.y.reshape((self.n, self.m, 2, last_dim))\n",
    "            pred_data_new, trap_data_new = sol_use[:, :, 0, :], sol_use[:, :, 1, :]\n",
    "            # set prey from timestep of interest as predator in y_prey\n",
    "            y_prey[:,:,1] = pred_data_new[:, :, -1]\n",
    "            # grab predator information from prey data\n",
    "            y_prey[:,:,0] = prey_data\n",
    "            y_prey = y_prey.flatten()\n",
    "            # prey solver, only grab single timestep\n",
    "            sol_prey = solve_ivp(synthetic_data.spatial_dynamics, y0=y_prey, t_span=[0,1], t_eval=np.linspace(0, 1, self.pts_per_sec), args=(self.n, self.m))\n",
    "            # create y0 for next run of trap solver, overwrite y0 and prey_data\n",
    "            y0 = np.zeros((self.n, self.m, 2))\n",
    "            sol_prey_use = sol_prey.y.reshape((self.n, self.m, 2, last_dim))\n",
    "            prey_data, predator_data = sol_prey_use[:, :, 0, :], sol_prey_use[:, :, 1, :]\n",
    "            y0[:,:,0] = predator_data[:, :, -1]\n",
    "            prey_data = prey_data[:, :, -1]\n",
    "            # initialize trap locations based on number of desired traps and density, re initialize per replacement time\n",
    "            y0[:,:,1] = trap_data_new[:,:,-1]\n",
    "            y0 = y0.flatten()\n",
    "            master_sol = np.concatenate((master_sol, sol_prey.y), 1)\n",
    "\n",
    "        master_sol = master_sol[:,100:].reshape(self.n, self.m,2,self.pts_per_sec*self.trap_replacement_rate)\n",
    "        \n",
    "        # Extract the last step predator and prey densities from the solution\n",
    "        self.prey_density , self.predator_density = master_sol[:, :, 0, -1], master_sol[:, :, 1, -1]\n",
    "\n",
    "        # Calculate reward based on the change in predator density\n",
    "        reward = -np.sum(self.predator_density)\n",
    "        if reward == 0:\n",
    "            reward = 1000\n",
    "\n",
    "        # Check termination condition\n",
    "        predator_sum_zero = np.sum(self.predator_density) == 0\n",
    "        # Check if the maximum number of steps is reached\n",
    "        max_steps_reached = self.current_step >= self.max_steps\n",
    "    \n",
    "        # Combine termination conditions\n",
    "        done = predator_sum_zero or max_steps_reached\n",
    "        \n",
    "        # Return next state, reward, and done flag (assuming no termination condition for now)\n",
    "        self.current_step += 1\n",
    "        print(f\"finished step {self.current_step}\")\n",
    "        return self.predator_density, self.prey_density, reward, done\n",
    "\n",
    "# define DQN\n",
    "class QNetwork(torch.nn.Module):\n",
    "    def __init__(self, num_actions, input_size):\n",
    "        super(QNetwork, self).__init__()\n",
    "        self.dense1 = torch.nn.Linear(input_size, 64)\n",
    "        self.dense2 = torch.nn.Linear(64, 64)\n",
    "        self.output_layer = torch.nn.Linear(64, num_actions)\n",
    "\n",
    "\n",
    "    def forward(self, state):\n",
    "        x = torch.nn.functional.relu(self.dense1(state))\n",
    "        x = torch.nn.functional.relu(self.dense2(x))\n",
    "        return self.output_layer(x)\n",
    "\n",
    "# Simple Q-learning algorithm with experience replay\n",
    "class QLearningAgent:\n",
    "    def __init__(self, m,n,input_size,num_traps):\n",
    "        self.num_actions = m * n\n",
    "        self.q_network = QNetwork(self.num_actions,input_size)\n",
    "        self.optimizer = torch.optim.Adam(self.q_network.parameters(), lr=0.001)\n",
    "        self.memory = []\n",
    "        self.m = m\n",
    "        self.n = n\n",
    "        self.num_traps = num_traps\n",
    "\n",
    "    def select_action(self, state):\n",
    "        # Epsilon-greedy policy\n",
    "        if np.random.rand() < 0.1:\n",
    "            # Explore: Randomly select trap locations\n",
    "            trap_indices = []\n",
    "            for _ in range(self.num_traps):\n",
    "                trap_indices.append((np.random.randint(self.n), np.random.randint(self.m)))\n",
    "            return trap_indices\n",
    "        else:\n",
    "            # Exploit: Select actions with highest Q-values\n",
    "            state_tensor = torch.tensor(state, dtype=torch.float32)\n",
    "            q_values = self.q_network(state_tensor)\n",
    "\n",
    "            # Select the top num_traps indices with highest Q-values\n",
    "            top_indices = torch.topk(q_values, self.num_traps).indices.tolist()\n",
    "            \n",
    "            # Convert indices to trap locations\n",
    "            trap_indices = []\n",
    "            for idx in top_indices:\n",
    "                i = idx // self.m\n",
    "                j = idx % self.m\n",
    "                trap_indices.append((i, j))\n",
    "            return trap_indices\n",
    "\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def experience_replay(self, batch_size=32):\n",
    "        if len(self.memory) < batch_size:\n",
    "            return\n",
    "\n",
    "        minibatch = np.random.choice(len(self.memory), batch_size, replace=False)\n",
    "        states, targets = [], []\n",
    "        for idx in minibatch:\n",
    "            state, action, reward, next_state, done = self.memory[idx]\n",
    "            states.append(state)\n",
    "            q_values = self.q_network(torch.tensor([state], dtype=torch.float32)).detach().numpy()[0]\n",
    "            if done:\n",
    "                q_values[action] = reward\n",
    "            else:\n",
    "                next_q_values = self.q_network(torch.tensor([next_state], dtype=torch.float32)).detach().numpy()[0]\n",
    "                q_values[action] = reward + 0.9 * np.max(next_q_values)\n",
    "            targets.append(q_values)\n",
    "        \n",
    "        states = np.array(states, dtype=np.float32)\n",
    "        targets = np.array(targets, dtype=np.float32)\n",
    "        \n",
    "        states_tensor = torch.tensor(states)\n",
    "        targets_tensor = torch.tensor(targets)\n",
    "        \n",
    "        self.optimizer.zero_grad()\n",
    "        q_values = self.q_network(states_tensor)\n",
    "        loss = torch.nn.functional.mse_loss(q_values, targets_tensor)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        \n",
    "# Training loop\n",
    "def train_agent(env, agent, num_episodes=1000):\n",
    "    for episode in range(num_episodes):\n",
    "        state = env.reset()\n",
    "        env.current_step = 0\n",
    "        total_reward = 0\n",
    "        done = False\n",
    "        while not done:\n",
    "            state = np.array(state).flatten()\n",
    "            action = agent.select_action(state)\n",
    "            next_state_prey, next_state_pred, reward, done = env.step(action)\n",
    "            next_state = np.concatenate((next_state_prey.flatten(), next_state_pred.flatten()))\n",
    "            agent.remember(state, action, reward, next_state, done)\n",
    "            agent.experience_replay()\n",
    "            state = next_state\n",
    "            total_reward += reward\n",
    "        print(f\"Episode {episode + 1}/{num_episodes}, Total Reward: {total_reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, IntSlider\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_predator_locations_single(state, n):\n",
    "    predator_density, prey_density = state[0], state[1]\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))  # One row, two columns\n",
    "    titles = ['Predator Grid', 'Prey Grid']\n",
    "    grids = [predator_density, prey_density]\n",
    "\n",
    "    for ax, title, grid in zip(axes, titles, grids):\n",
    "        im = ax.imshow(grid, cmap='YlGn')\n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel('Column')\n",
    "        ax.set_ylabel('Row')\n",
    "        ax.axis('on')\n",
    "        plt.colorbar(im, ax=ax, orientation='vertical', fraction=0.05, pad=0.04)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "\n",
    "def predict(env, agent):\n",
    "    state = env.reset()\n",
    "    # # plot the initialized pred prey spread\n",
    "    # plot_predator_locations_single(state,env.n)\n",
    "    state = np.array(state).flatten()\n",
    "    action = agent.select_action(state)\n",
    "    print(\"Predicted trap locations for next episode:\", action)\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished step 1\n",
      "finished step 2\n",
      "finished step 3\n",
      "finished step 4\n",
      "finished step 5\n",
      "finished step 6\n",
      "finished step 7\n",
      "finished step 8\n",
      "finished step 9\n",
      "finished step 10\n",
      "finished step 11\n",
      "finished step 12\n",
      "finished step 13\n",
      "finished step 14\n",
      "finished step 15\n",
      "finished step 16\n",
      "finished step 17\n",
      "finished step 18\n",
      "finished step 19\n",
      "finished step 20\n",
      "finished step 21\n",
      "finished step 22\n",
      "finished step 23\n",
      "finished step 24\n",
      "finished step 25\n",
      "finished step 26\n",
      "finished step 27\n",
      "finished step 28\n",
      "finished step 29\n",
      "finished step 30\n",
      "finished step 31\n",
      "finished step 32\n",
      "finished step 33\n",
      "finished step 34\n",
      "finished step 35\n",
      "finished step 36\n",
      "finished step 37\n",
      "finished step 38\n",
      "finished step 39\n",
      "finished step 40\n",
      "finished step 41\n",
      "finished step 42\n",
      "finished step 43\n",
      "finished step 44\n",
      "finished step 45\n",
      "finished step 46\n",
      "finished step 47\n",
      "finished step 48\n",
      "finished step 49\n",
      "finished step 50\n",
      "finished step 51\n",
      "finished step 52\n",
      "finished step 53\n",
      "finished step 54\n",
      "finished step 55\n",
      "finished step 56\n",
      "finished step 57\n",
      "finished step 58\n",
      "finished step 59\n",
      "finished step 60\n",
      "finished step 61\n",
      "finished step 62\n",
      "finished step 63\n",
      "finished step 64\n",
      "finished step 65\n",
      "finished step 66\n",
      "finished step 67\n",
      "finished step 68\n",
      "finished step 69\n",
      "finished step 70\n",
      "finished step 71\n",
      "finished step 72\n",
      "finished step 73\n",
      "finished step 74\n",
      "finished step 75\n",
      "finished step 76\n",
      "finished step 77\n",
      "finished step 78\n",
      "finished step 79\n",
      "finished step 80\n",
      "finished step 81\n",
      "finished step 82\n",
      "finished step 83\n",
      "finished step 84\n",
      "finished step 85\n",
      "finished step 86\n",
      "finished step 87\n",
      "finished step 88\n",
      "finished step 89\n",
      "finished step 90\n",
      "finished step 91\n",
      "finished step 92\n",
      "finished step 93\n",
      "finished step 94\n",
      "finished step 95\n",
      "finished step 96\n",
      "finished step 97\n",
      "finished step 98\n",
      "finished step 99\n",
      "finished step 100\n",
      "finished step 101\n",
      "finished step 102\n",
      "finished step 103\n",
      "finished step 104\n",
      "finished step 105\n",
      "finished step 106\n",
      "finished step 107\n",
      "finished step 108\n",
      "finished step 109\n",
      "finished step 110\n",
      "finished step 111\n",
      "finished step 112\n",
      "finished step 113\n",
      "finished step 114\n",
      "finished step 115\n",
      "finished step 116\n",
      "finished step 117\n",
      "finished step 118\n",
      "finished step 119\n",
      "finished step 120\n",
      "finished step 121\n",
      "finished step 122\n",
      "finished step 123\n",
      "finished step 124\n",
      "finished step 125\n",
      "finished step 126\n",
      "finished step 127\n",
      "finished step 128\n",
      "finished step 129\n",
      "finished step 130\n",
      "finished step 131\n",
      "finished step 132\n",
      "finished step 133\n",
      "finished step 134\n",
      "finished step 135\n",
      "finished step 136\n",
      "finished step 137\n",
      "finished step 138\n",
      "finished step 139\n",
      "finished step 140\n",
      "finished step 141\n",
      "finished step 142\n",
      "finished step 143\n",
      "finished step 144\n",
      "finished step 145\n",
      "finished step 146\n",
      "finished step 147\n",
      "finished step 148\n",
      "finished step 149\n",
      "finished step 150\n",
      "finished step 151\n",
      "finished step 152\n",
      "finished step 153\n",
      "finished step 154\n",
      "finished step 155\n",
      "finished step 156\n",
      "finished step 157\n",
      "finished step 158\n",
      "finished step 159\n",
      "finished step 160\n",
      "finished step 161\n",
      "finished step 162\n",
      "finished step 163\n",
      "finished step 164\n",
      "finished step 165\n",
      "finished step 166\n",
      "finished step 167\n",
      "finished step 168\n",
      "finished step 169\n",
      "finished step 170\n",
      "finished step 171\n",
      "finished step 172\n",
      "finished step 173\n",
      "finished step 174\n",
      "finished step 175\n",
      "finished step 176\n",
      "finished step 177\n",
      "finished step 178\n",
      "finished step 179\n",
      "finished step 180\n",
      "finished step 181\n",
      "finished step 182\n",
      "finished step 183\n",
      "finished step 184\n",
      "finished step 185\n",
      "finished step 186\n",
      "finished step 187\n",
      "finished step 188\n",
      "finished step 189\n",
      "finished step 190\n",
      "finished step 191\n",
      "finished step 192\n",
      "finished step 193\n",
      "finished step 194\n",
      "finished step 195\n",
      "finished step 196\n",
      "finished step 197\n",
      "finished step 198\n",
      "finished step 199\n",
      "finished step 200\n",
      "finished step 201\n",
      "finished step 202\n",
      "finished step 203\n",
      "finished step 204\n",
      "finished step 205\n",
      "finished step 206\n",
      "finished step 207\n",
      "finished step 208\n",
      "finished step 209\n",
      "finished step 210\n",
      "finished step 211\n",
      "finished step 212\n",
      "finished step 213\n",
      "finished step 214\n",
      "finished step 215\n",
      "finished step 216\n",
      "finished step 217\n",
      "finished step 218\n",
      "finished step 219\n",
      "finished step 220\n",
      "finished step 221\n",
      "finished step 222\n",
      "finished step 223\n",
      "finished step 224\n",
      "finished step 225\n",
      "finished step 226\n",
      "finished step 227\n",
      "finished step 228\n",
      "finished step 229\n",
      "finished step 230\n",
      "finished step 231\n",
      "finished step 232\n",
      "finished step 233\n",
      "finished step 234\n",
      "finished step 235\n",
      "finished step 236\n",
      "finished step 237\n",
      "finished step 238\n",
      "finished step 239\n",
      "finished step 240\n",
      "finished step 241\n",
      "finished step 242\n",
      "finished step 243\n",
      "finished step 244\n",
      "finished step 245\n",
      "finished step 246\n",
      "finished step 247\n",
      "finished step 248\n",
      "finished step 249\n",
      "finished step 250\n",
      "finished step 251\n",
      "finished step 252\n",
      "finished step 253\n",
      "finished step 254\n",
      "finished step 255\n",
      "finished step 256\n",
      "finished step 257\n",
      "finished step 258\n",
      "finished step 259\n",
      "finished step 260\n",
      "finished step 261\n",
      "finished step 262\n",
      "finished step 263\n",
      "finished step 264\n",
      "finished step 265\n",
      "finished step 266\n",
      "finished step 267\n",
      "finished step 268\n",
      "finished step 269\n",
      "finished step 270\n",
      "finished step 271\n",
      "finished step 272\n",
      "finished step 273\n",
      "finished step 274\n",
      "finished step 275\n",
      "finished step 276\n",
      "finished step 277\n",
      "finished step 278\n",
      "finished step 279\n",
      "finished step 280\n",
      "finished step 281\n",
      "finished step 282\n",
      "finished step 283\n",
      "finished step 284\n",
      "finished step 285\n",
      "finished step 286\n",
      "finished step 287\n",
      "finished step 288\n",
      "finished step 289\n",
      "finished step 290\n",
      "finished step 291\n",
      "finished step 292\n",
      "finished step 293\n",
      "finished step 294\n",
      "finished step 295\n",
      "finished step 296\n",
      "finished step 297\n",
      "finished step 298\n",
      "finished step 299\n",
      "finished step 300\n",
      "finished step 301\n",
      "finished step 302\n",
      "finished step 303\n",
      "finished step 304\n",
      "finished step 305\n",
      "finished step 306\n",
      "finished step 307\n",
      "finished step 308\n",
      "finished step 309\n",
      "finished step 310\n",
      "finished step 311\n",
      "finished step 312\n",
      "finished step 313\n",
      "finished step 314\n",
      "finished step 315\n",
      "finished step 316\n",
      "finished step 317\n",
      "finished step 318\n",
      "finished step 319\n",
      "finished step 320\n",
      "finished step 321\n",
      "finished step 322\n",
      "finished step 323\n",
      "finished step 324\n",
      "finished step 325\n",
      "finished step 326\n",
      "finished step 327\n",
      "finished step 328\n",
      "finished step 329\n",
      "finished step 330\n",
      "finished step 331\n",
      "finished step 332\n",
      "finished step 333\n",
      "finished step 334\n",
      "finished step 335\n",
      "finished step 336\n",
      "finished step 337\n",
      "finished step 338\n",
      "finished step 339\n",
      "finished step 340\n",
      "finished step 341\n",
      "finished step 342\n",
      "finished step 343\n",
      "finished step 344\n",
      "finished step 345\n",
      "finished step 346\n",
      "finished step 347\n",
      "finished step 348\n",
      "finished step 349\n",
      "finished step 350\n",
      "finished step 351\n",
      "finished step 352\n",
      "finished step 353\n",
      "finished step 354\n",
      "finished step 355\n",
      "finished step 356\n",
      "finished step 357\n",
      "finished step 358\n",
      "finished step 359\n",
      "finished step 360\n",
      "finished step 361\n",
      "finished step 362\n",
      "finished step 363\n",
      "finished step 364\n",
      "finished step 365\n",
      "finished step 366\n",
      "finished step 367\n",
      "finished step 368\n",
      "finished step 369\n",
      "finished step 370\n",
      "finished step 371\n",
      "finished step 372\n",
      "finished step 373\n",
      "finished step 374\n",
      "finished step 375\n",
      "finished step 376\n",
      "finished step 377\n",
      "finished step 378\n",
      "finished step 379\n",
      "finished step 380\n",
      "finished step 381\n",
      "finished step 382\n",
      "finished step 383\n",
      "finished step 384\n",
      "finished step 385\n",
      "finished step 386\n",
      "finished step 387\n",
      "finished step 388\n",
      "finished step 389\n",
      "finished step 390\n",
      "finished step 391\n",
      "finished step 392\n",
      "finished step 393\n",
      "finished step 394\n",
      "finished step 395\n",
      "finished step 396\n",
      "finished step 397\n",
      "finished step 398\n",
      "finished step 399\n",
      "finished step 400\n",
      "finished step 401\n",
      "finished step 402\n",
      "finished step 403\n",
      "finished step 404\n",
      "finished step 405\n",
      "finished step 406\n",
      "finished step 407\n",
      "finished step 408\n",
      "finished step 409\n",
      "finished step 410\n",
      "finished step 411\n",
      "finished step 412\n",
      "finished step 413\n",
      "finished step 414\n",
      "finished step 415\n",
      "finished step 416\n",
      "finished step 417\n",
      "finished step 418\n",
      "finished step 419\n",
      "finished step 420\n",
      "finished step 421\n",
      "finished step 422\n",
      "finished step 423\n",
      "finished step 424\n",
      "finished step 425\n",
      "finished step 426\n",
      "finished step 427\n",
      "finished step 428\n",
      "finished step 429\n",
      "finished step 430\n",
      "finished step 431\n",
      "finished step 432\n",
      "finished step 433\n",
      "finished step 434\n",
      "finished step 435\n",
      "finished step 436\n",
      "finished step 437\n",
      "finished step 438\n",
      "finished step 439\n",
      "finished step 440\n",
      "finished step 441\n",
      "finished step 442\n",
      "finished step 443\n",
      "finished step 444\n",
      "finished step 445\n",
      "finished step 446\n",
      "finished step 447\n",
      "finished step 448\n",
      "finished step 449\n",
      "finished step 450\n",
      "finished step 451\n",
      "finished step 452\n",
      "finished step 453\n",
      "finished step 454\n",
      "finished step 455\n",
      "finished step 456\n",
      "finished step 457\n",
      "finished step 458\n",
      "finished step 459\n",
      "finished step 460\n",
      "finished step 461\n",
      "finished step 462\n",
      "finished step 463\n",
      "finished step 464\n",
      "finished step 465\n",
      "finished step 466\n",
      "finished step 467\n",
      "finished step 468\n",
      "finished step 469\n",
      "finished step 470\n",
      "finished step 471\n",
      "finished step 472\n",
      "finished step 473\n",
      "finished step 474\n",
      "finished step 475\n",
      "finished step 476\n",
      "finished step 477\n",
      "finished step 478\n",
      "finished step 479\n",
      "finished step 480\n",
      "finished step 481\n",
      "finished step 482\n",
      "finished step 483\n",
      "finished step 484\n",
      "finished step 485\n",
      "finished step 486\n",
      "finished step 487\n",
      "finished step 488\n",
      "finished step 489\n",
      "finished step 490\n",
      "finished step 491\n",
      "finished step 492\n",
      "finished step 493\n",
      "finished step 494\n",
      "finished step 495\n",
      "finished step 496\n",
      "finished step 497\n",
      "finished step 498\n",
      "finished step 499\n",
      "finished step 500\n",
      "finished step 501\n",
      "finished step 502\n",
      "finished step 503\n",
      "finished step 504\n",
      "finished step 505\n",
      "finished step 506\n",
      "finished step 507\n",
      "finished step 508\n",
      "finished step 509\n",
      "finished step 510\n",
      "finished step 511\n",
      "finished step 512\n",
      "finished step 513\n",
      "finished step 514\n",
      "finished step 515\n",
      "finished step 516\n",
      "finished step 517\n",
      "finished step 518\n",
      "finished step 519\n",
      "finished step 520\n",
      "finished step 521\n",
      "finished step 522\n",
      "finished step 523\n",
      "finished step 524\n",
      "finished step 525\n",
      "finished step 526\n",
      "finished step 527\n",
      "finished step 528\n",
      "finished step 529\n",
      "finished step 530\n",
      "finished step 531\n",
      "finished step 532\n",
      "finished step 533\n",
      "finished step 534\n",
      "finished step 535\n",
      "finished step 536\n",
      "finished step 537\n",
      "finished step 538\n",
      "finished step 539\n",
      "finished step 540\n",
      "finished step 541\n",
      "finished step 542\n",
      "finished step 543\n",
      "finished step 544\n",
      "finished step 545\n",
      "finished step 546\n",
      "finished step 547\n",
      "finished step 548\n",
      "finished step 549\n",
      "finished step 550\n",
      "finished step 551\n",
      "finished step 552\n",
      "finished step 553\n",
      "finished step 554\n",
      "finished step 555\n",
      "finished step 556\n",
      "finished step 557\n",
      "finished step 558\n",
      "finished step 559\n",
      "finished step 560\n",
      "finished step 561\n",
      "finished step 562\n",
      "finished step 563\n",
      "finished step 564\n",
      "finished step 565\n",
      "finished step 566\n",
      "finished step 567\n",
      "finished step 568\n",
      "finished step 569\n",
      "finished step 570\n",
      "finished step 571\n",
      "finished step 572\n",
      "finished step 573\n",
      "finished step 574\n",
      "finished step 575\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-959aa0a6abfe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Train the agent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrain_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_episodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Predict and display predictions in interactive slider\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-544d804b9b75>\u001b[0m in \u001b[0;36mtrain_agent\u001b[0;34m(env, agent, num_episodes)\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m             \u001b[0mnext_state_prey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m             \u001b[0mnext_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_state_prey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremember\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-544d804b9b75>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrap_replacement_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;31m# trap solver, only grab single timestep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0msol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolve_ivp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msynthetic_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspatial_dynamics_traps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_span\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpts_per_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m             \u001b[0;31m# prey solver y0 creation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0my_prey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/scipy/integrate/_ivp/ivp.py\u001b[0m in \u001b[0;36msolve_ivp\u001b[0;34m(fun, t_span, y0, method, t_eval, dense_output, events, vectorized, args, **options)\u001b[0m\n\u001b[1;32m    589\u001b[0m     \u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'finished'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/scipy/integrate/_ivp/base.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/scipy/integrate/_ivp/rk.py\u001b[0m in \u001b[0;36m_step_impl\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0mh_abs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m             y_new, f_new = rk_step(self.fun, t, y, self.f, h, self.A,\n\u001b[0m\u001b[1;32m    145\u001b[0m                                    self.B, self.C, self.K)\n\u001b[1;32m    146\u001b[0m             \u001b[0mscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0matol\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mrtol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/scipy/integrate/_ivp/rk.py\u001b[0m in \u001b[0;36mrk_step\u001b[0;34m(fun, t, y, f, h, A, B, C, K)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mdy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mK\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0my_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/scipy/integrate/_ivp/base.py\u001b[0m in \u001b[0;36mfun\u001b[0;34m(t, y)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnfev\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/scipy/integrate/_ivp/base.py\u001b[0m in \u001b[0;36mfun_wrapped\u001b[0;34m(t, y)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/scipy/integrate/_ivp/ivp.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t, x, fun)\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuggestion_tuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m         \u001b[0mfun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m         \u001b[0mjac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'jac'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjac\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/288_invasive_species/Model_Generation/synthetic_data.py\u001b[0m in \u001b[0;36mspatial_dynamics_traps\u001b[0;34m(t, y, n, m)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0;31m# diffusion is estimated through finite differencing method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0;31m# according to https://levelup.gitconnected.com/solving-2d-heat-equation-numerically-using-python-3334004aa01a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m             \u001b[0mdelta_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdelta\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m             \u001b[0mdiffusion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdelta_t\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdelta\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mk\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mk\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mk\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m4\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mk\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0;31m# Contribution from decay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Create environment and agent\n",
    "env = TrapEnvironment()\n",
    "agent = QLearningAgent(n=env.n, m= env.m, input_size=env.n * env.m*2, num_traps=env.num_traps)\n",
    "\n",
    "# Train the agent\n",
    "train_agent(env, agent,num_episodes=25)\n",
    "\n",
    "# Predict and display predictions in interactive slider\n",
    "trap_locations = predict(env, agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted trap locations for next episode: [(0, 22), (3, 21), (24, 24), (20, 23), (10, 14), (11, 9), (10, 3), (21, 21), (19, 8), (10, 11), (7, 21), (3, 11), (1, 14), (20, 7), (15, 5), (11, 4), (13, 9), (17, 22), (20, 15), (21, 5)]\n",
      "(1250, 2500)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69c3d548713b4d1087c4d03543560405",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='../Data/val_predict.npy', description='file_loc'), IntSlider(value=0, descriâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_predator_locations_at_timestep_here(file_loc, timestep)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# display predictions\n",
    "trap_locations = predict(env, agent)\n",
    "max_timestep = 24\n",
    "\n",
    "\n",
    "# run and save a few timesteps of trap behavior with those locations\n",
    "def generate_traps_next(env, trap_locations=trap_locations, num_traj=200, num_replacements=2, len_traj=50, pts_per_sec=100, save_loc='../Data/val_predict.npy', prey_range=(1, 5), predator_range=(1, 3)):\n",
    "    # initialization stuff\n",
    "    n = 25\n",
    "    m = 25\n",
    "    replacement_window = int(len_traj/num_replacements)\n",
    "    dataset = np.zeros((num_traj, n * m * 2, len_traj * pts_per_sec))  # That will store each simulation\n",
    "    t_span = [0, replacement_window]\n",
    "    t_eval = np.linspace(0, replacement_window, replacement_window * pts_per_sec)  # Time vector\n",
    "\n",
    "    # Change this line to configure how much you downsample the data, and the final time range\n",
    "    downsample_rate = int(len(t_eval) / (replacement_window * pts_per_sec))\n",
    "    idx = np.arange(0, len(t_eval), downsample_rate)\n",
    "\n",
    "    # Generate random initial values for prey and predator populations within the specified ranges\n",
    "    y0 = np.zeros((n, m, 2))\n",
    "\n",
    "    # Generating inital points for both populations\n",
    "    # set prey (invasive species) location at last timestep of initialization for new object where the traps will be the predators\n",
    "    y0[:,:,0] = env.predator_density\n",
    "    prey_data = env.prey_density\n",
    "\n",
    "    # initialize trap locations based on predictions\n",
    "    for i,j in trap_locations:\n",
    "        y0[i, j, 1] = 10\n",
    "    y0 = y0.flatten()\n",
    "\n",
    "    # modify a run s.t. each timestep consists of two solvers: one for traps and one for prey\n",
    "    # sol.y has shape (2 * n * m, 2500) with one row representing the prey(t) function and the other representing the predator(t)function\n",
    "    # sol_use = None\n",
    "    master_sol = np.ndarray((n*m*2,pts_per_sec))\n",
    "\n",
    "\n",
    "    for _ in range(replacement_window):\n",
    "        # trap solver, only grab single timestep\n",
    "        sol = solve_ivp(synthetic_data.spatial_dynamics_traps, y0=y0, t_span=[0,1], t_eval=np.linspace(0, 1, pts_per_sec), args=(n, m))\n",
    "        # prey solver y0 creation\n",
    "        y_prey = np.zeros((n, m, 2))\n",
    "        last_dim = int(pts_per_sec)\n",
    "        sol_use = sol.y.reshape((n, m, 2, last_dim))\n",
    "        pred_data_new, trap_data_new = sol_use[:, :, 0, :], sol_use[:, :, 1, :]\n",
    "        # set prey from timestep of interest as predator in y_prey\n",
    "        y_prey[:,:,1] = pred_data_new[:, :, -1]\n",
    "        # grab predator information from prey data\n",
    "        y_prey[:,:,0] = prey_data\n",
    "        y_prey = y_prey.flatten()\n",
    "        # prey solver, only grab single timestep\n",
    "        sol_prey = solve_ivp(synthetic_data.spatial_dynamics, y0=y_prey, t_span=[0,1], t_eval=np.linspace(0, 1, pts_per_sec), args=(n, m))\n",
    "        # create y0 for next run of trap solver, overwrite y0 and prey_data\n",
    "        y0 = np.zeros((n, m, 2))\n",
    "        sol_prey_use = sol_prey.y.reshape((n, m, 2, last_dim))\n",
    "        prey_data, predator_data = sol_prey_use[:, :, 0, :], sol_prey_use[:, :, 1, :]\n",
    "        y0[:,:,0] = predator_data[:, :, -1]\n",
    "        prey_data = prey_data[:, :, -1]\n",
    "        # initialize trap locations based on number of desired traps and density, re initialize per replacement time\n",
    "        y0[:,:,1] = trap_data_new[:,:,-1]\n",
    "        y0 = y0.flatten()\n",
    "        master_sol = np.concatenate((master_sol, sol_prey.y), 1)\n",
    "\n",
    "    # save master sol object\n",
    "    print(master_sol[:,100:].shape)\n",
    "    np.save(save_loc, master_sol[:,100:])\n",
    "\n",
    "\n",
    "def plot_predator_locations_at_timestep_here(file_loc, timestep):\n",
    "    dataset = np.load(file_loc)\n",
    "    data = dataset.reshape((25, 25, 2, 2500))\n",
    "    plot_predator_locations_here(data, timestep*50)\n",
    "\n",
    "def plot_predator_locations_here(grid, timestep):\n",
    "    #Get the min and max of all your data\n",
    "    _min, _max = np.amin(grid), np.amax(grid)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(2, 1, 1)\n",
    "    #Add the vmin and vmax arguments to set the color scale\n",
    "    ax.imshow(grid[:, :, 0, timestep], cmap=plt.cm.YlGn, vmin = _min, vmax = _max)\n",
    "    ax2 = fig.add_subplot(2, 1, 2)\n",
    "    #Add the vmin and vmax arguments to set the color scale\n",
    "    ax2.imshow(grid[:, :, 1, timestep], cmap=plt.cm.YlGn, vmin = _min, vmax = _max)\n",
    "    plt.show()\n",
    "\n",
    "generate_traps_next(env,trap_locations)\n",
    "\n",
    "# Create an interactive slider\n",
    "interact(plot_predator_locations_at_timestep_here, file_loc='../Data/val_predict.npy', timestep=IntSlider(min=0, max=max_timestep, step=1, value=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted trap locations for next episode: [(15, 16), (13, 22), (14, 11), (10, 3), (13, 0), (21, 14), (23, 20), (20, 7), (17, 10), (15, 5), (19, 8), (22, 3), (3, 1), (11, 9), (20, 23), (5, 5), (21, 5), (3, 14), (20, 15), (7, 21)]\n",
      "purple monster [(15, 16), (13, 22), (14, 11), (10, 3), (13, 0), (21, 14), (23, 20), (20, 7), (17, 10), (15, 5), (19, 8), (22, 3), (3, 1), (11, 9), (20, 23), (5, 5), (21, 5), (3, 14), (20, 15), (7, 21)]\n",
      "what is going on\n",
      "Predicted trap locations for next episode: [(15, 16), (13, 22), (14, 11), (10, 3), (13, 0), (21, 14), (23, 20), (20, 7), (17, 10), (15, 5), (19, 8), (22, 3), (3, 1), (11, 9), (20, 23), (5, 5), (21, 5), (3, 14), (20, 15), (7, 21)]\n",
      "0 cookie\n",
      "Predicted trap locations for next episode: [(17, 15), (6, 24), (18, 19), (2, 16), (7, 6), (12, 4), (6, 6), (11, 6), (17, 10), (0, 7), (9, 4), (18, 14), (19, 24), (9, 11), (6, 11), (3, 4), (24, 8), (2, 17), (11, 7), (20, 6)]\n",
      "1 cookie\n",
      "Predicted trap locations for next episode: [(13, 22), (10, 3), (15, 16), (14, 11), (13, 0), (3, 1), (21, 14), (23, 20), (20, 7), (17, 10), (19, 8), (15, 5), (5, 5), (20, 23), (11, 9), (1, 14), (20, 15), (7, 21), (21, 5), (16, 22)]\n",
      "2 cookie\n",
      "Predicted trap locations for next episode: [(13, 22), (10, 3), (3, 1), (15, 16), (14, 11), (13, 0), (21, 14), (23, 20), (19, 8), (20, 7), (1, 14), (15, 5), (5, 5), (17, 10), (11, 9), (20, 23), (20, 15), (3, 21), (17, 22), (9, 15)]\n",
      "3 cookie\n",
      "Predicted trap locations for next episode: [(13, 22), (10, 3), (3, 1), (15, 16), (13, 0), (14, 11), (1, 14), (19, 8), (21, 14), (20, 7), (23, 20), (5, 5), (15, 5), (11, 9), (17, 10), (20, 23), (3, 21), (20, 15), (0, 22), (17, 22)]\n",
      "4 cookie\n",
      "Predicted trap locations for next episode: [(13, 22), (10, 3), (3, 1), (1, 14), (19, 8), (11, 9), (13, 0), (15, 5), (15, 16), (20, 23), (5, 5), (14, 11), (21, 14), (20, 7), (3, 21), (17, 10), (23, 20), (0, 22), (20, 15), (16, 22)]\n",
      "5 cookie\n",
      "Predicted trap locations for next episode: [(9, 14), (0, 4), (19, 7), (5, 3), (1, 14), (5, 21), (21, 16), (7, 12), (17, 5), (21, 3), (22, 14), (20, 20), (9, 17), (2, 15), (17, 7), (1, 5), (12, 11), (12, 24), (5, 11), (3, 12)]\n",
      "6 cookie\n",
      "Predicted trap locations for next episode: [(13, 22), (3, 1), (11, 9), (15, 5), (10, 3), (19, 8), (1, 14), (20, 23), (16, 8), (5, 5), (21, 21), (3, 21), (14, 11), (13, 0), (20, 7), (0, 22), (16, 22), (5, 14), (4, 20), (16, 18)]\n",
      "7 cookie\n",
      "Predicted trap locations for next episode: [(13, 22), (3, 1), (15, 5), (11, 9), (19, 8), (20, 23), (10, 3), (1, 14), (16, 8), (3, 21), (21, 21), (16, 18), (5, 5), (5, 14), (14, 11), (16, 22), (4, 20), (13, 0), (0, 22), (20, 7)]\n",
      "8 cookie\n",
      "Predicted trap locations for next episode: [(13, 22), (3, 1), (15, 5), (19, 8), (11, 9), (20, 23), (16, 8), (10, 3), (1, 14), (16, 18), (3, 21), (21, 21), (5, 14), (4, 20), (16, 22), (0, 15), (5, 5), (14, 11), (13, 0), (0, 22)]\n",
      "9 cookie\n",
      "Predicted trap locations for next episode: [(13, 22), (3, 1), (19, 8), (15, 5), (11, 9), (20, 23), (16, 8), (10, 3), (1, 14), (16, 18), (3, 21), (21, 21), (5, 14), (4, 20), (16, 22), (2, 16), (0, 15), (14, 11), (2, 10), (5, 5)]\n",
      "10 cookie\n",
      "Predicted trap locations for next episode: [(13, 22), (19, 8), (3, 1), (15, 5), (11, 9), (20, 23), (16, 8), (16, 18), (1, 14), (10, 3), (3, 21), (21, 21), (5, 14), (2, 16), (16, 22), (4, 20), (0, 15), (2, 10), (6, 6), (13, 9)]\n",
      "11 cookie\n",
      "Predicted trap locations for next episode: [(13, 10), (4, 10), (22, 24), (23, 0), (7, 5), (8, 21), (19, 17), (3, 20), (20, 8), (16, 15), (1, 15), (12, 17), (21, 19), (21, 7), (5, 15), (15, 16), (13, 10), (22, 17), (5, 5), (13, 4)]\n",
      "12 cookie\n",
      "Predicted trap locations for next episode: [(13, 22), (19, 8), (11, 9), (3, 1), (15, 5), (16, 8), (20, 23), (3, 21), (16, 18), (21, 21), (2, 16), (16, 22), (1, 14), (5, 14), (4, 20), (10, 3), (2, 10), (0, 15), (4, 16), (6, 6)]\n",
      "13 cookie\n",
      "Predicted trap locations for next episode: [(13, 22), (19, 8), (3, 1), (11, 9), (15, 5), (16, 8), (20, 23), (16, 18), (21, 21), (2, 16), (3, 21), (16, 22), (4, 20), (1, 14), (5, 14), (2, 10), (10, 3), (0, 15), (4, 16), (6, 6)]\n",
      "14 cookie\n",
      "Predicted trap locations for next episode: [(13, 22), (19, 8), (3, 1), (11, 9), (15, 5), (16, 8), (20, 23), (2, 16), (21, 21), (16, 18), (3, 21), (16, 22), (4, 20), (1, 14), (5, 14), (2, 10), (10, 3), (4, 16), (6, 6), (0, 15)]\n",
      "15 cookie\n",
      "Predicted trap locations for next episode: [(13, 22), (19, 8), (3, 1), (11, 9), (15, 5), (16, 8), (20, 23), (2, 16), (21, 21), (16, 18), (3, 21), (16, 22), (4, 20), (2, 10), (1, 14), (5, 14), (10, 3), (6, 6), (4, 16), (13, 9)]\n",
      "16 cookie\n",
      "Predicted trap locations for next episode: [(13, 22), (19, 8), (3, 1), (11, 9), (15, 5), (16, 8), (20, 23), (2, 16), (21, 21), (16, 18), (16, 22), (3, 21), (2, 10), (4, 20), (1, 14), (5, 14), (6, 6), (10, 3), (4, 16), (13, 9)]\n",
      "17 cookie\n",
      "Predicted trap locations for next episode: [(13, 22), (19, 8), (3, 1), (11, 9), (15, 5), (16, 8), (20, 23), (2, 16), (21, 21), (16, 18), (16, 22), (3, 21), (2, 10), (4, 20), (1, 14), (5, 14), (6, 6), (13, 9), (10, 3), (4, 16)]\n",
      "18 cookie\n",
      "Predicted trap locations for next episode: [(13, 22), (19, 8), (3, 1), (11, 9), (15, 5), (20, 23), (16, 8), (2, 16), (21, 21), (16, 18), (16, 22), (3, 21), (2, 10), (4, 20), (1, 14), (5, 14), (6, 6), (13, 9), (10, 3), (4, 16)]\n",
      "19 cookie\n",
      "Predicted trap locations for next episode: [(13, 22), (19, 8), (11, 9), (3, 1), (15, 5), (20, 23), (16, 8), (2, 16), (21, 21), (16, 22), (16, 18), (3, 21), (2, 10), (4, 20), (1, 14), (6, 6), (5, 14), (13, 9), (10, 3), (4, 16)]\n",
      "20 cookie\n",
      "Predicted trap locations for next episode: [(13, 22), (19, 8), (11, 9), (3, 1), (15, 5), (20, 23), (16, 8), (2, 16), (16, 22), (21, 21), (16, 18), (3, 21), (2, 10), (4, 20), (6, 6), (1, 14), (5, 14), (13, 9), (10, 3), (4, 16)]\n",
      "21 cookie\n",
      "Predicted trap locations for next episode: [(13, 22), (19, 8), (11, 9), (3, 1), (15, 5), (20, 23), (16, 8), (2, 16), (16, 22), (21, 21), (16, 18), (3, 21), (2, 10), (6, 6), (4, 20), (1, 14), (13, 9), (5, 14), (10, 3), (4, 16)]\n",
      "22 cookie\n",
      "Predicted trap locations for next episode: [(13, 22), (19, 8), (11, 9), (3, 1), (15, 5), (20, 23), (16, 8), (2, 16), (16, 22), (21, 21), (16, 18), (3, 21), (2, 10), (6, 6), (4, 20), (1, 14), (13, 9), (5, 14), (10, 3), (4, 16)]\n",
      "23 cookie\n",
      "Predicted trap locations for next episode: [(15, 19), (5, 24), (19, 20), (4, 10), (6, 18), (13, 13), (2, 23), (23, 22), (19, 6), (17, 6), (23, 15), (14, 9), (22, 8), (23, 3), (16, 15), (9, 6), (16, 18), (14, 23), (8, 8), (4, 2)]\n",
      "24 cookie\n",
      "Predicted trap locations for next episode: [(13, 22), (19, 8), (11, 9), (3, 1), (15, 5), (20, 23), (16, 8), (16, 22), (2, 16), (21, 21), (16, 18), (2, 10), (6, 6), (3, 21), (1, 14), (5, 14), (4, 20), (13, 9), (4, 16), (10, 3)]\n",
      "(1250, 5000)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "925618282eda4315ab699d1337a202b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='../Data/val_predict.npy', description='file_loc'), IntSlider(value=0, descriâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_predator_locations_at_timestep_here(file_loc, timestep)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def predict(env, agent):\n",
    "    state = (env.predator_density, env.prey_density)\n",
    "    # # plot the initialized pred prey spread\n",
    "    # plot_predator_locations_single(state,env.n)\n",
    "    state = np.array(state).flatten()\n",
    "    action = agent.select_action(state)\n",
    "    print(\"Predicted trap locations for next episode:\", action)\n",
    "    return action\n",
    "\n",
    "# display predictions\n",
    "env.reset()\n",
    "trap_locations = predict(env, agent)\n",
    "max_timestep = 49\n",
    "\n",
    "\n",
    "# run and save a few timesteps of trap behavior with those locations\n",
    "def generate_traps_next(env, num_traj=200, num_replacements=25, len_traj=50, pts_per_sec=100, save_loc='../Data/val_predict.npy', prey_range=(1, 5), predator_range=(1, 3)):\n",
    "    # initialization stuff\n",
    "    n = 25\n",
    "    m = 25\n",
    "    replacement_window = int(len_traj/num_replacements)\n",
    "    t_eval = np.linspace(0, replacement_window, replacement_window * pts_per_sec)  # Time vector\n",
    "\n",
    "    # Change this line to configure how much you downsample the data, and the final time range\n",
    "    downsample_rate = int(len(t_eval) / (replacement_window * pts_per_sec))\n",
    "    idx = np.arange(0, len(t_eval), downsample_rate)\n",
    "\n",
    "    # Generate random initial values for prey and predator populations within the specified ranges\n",
    "    y0 = np.zeros((n, m, 2))\n",
    "\n",
    "    # Generating inital points for both populations\n",
    "    # set prey (invasive species) location at last timestep of initialization for new object where the traps will be the predators\n",
    "    y0[:,:,0] = env.predator_density\n",
    "    prey_data = env.prey_density\n",
    "\n",
    "    # initialize trap locations based on predictions\n",
    "    trap_locations = predict(env, agent)\n",
    "    for i,j in trap_locations:\n",
    "        y0[i, j, 1] = 10\n",
    "    y0 = y0.flatten()\n",
    "\n",
    "    # modify a run s.t. each timestep consists of two solvers: one for traps and one for prey\n",
    "    # sol.y has shape (2 * n * m, 2500) with one row representing the prey(t) function and the other representing the predator(t)function\n",
    "    # sol_use = None\n",
    "    master_sol = np.ndarray((n*m*2,pts_per_sec))\n",
    "\n",
    "    for _ in range(num_replacements):\n",
    "        # replace trap positions, creating new y0\n",
    "        y0 = np.reshape(y0, (n, m, 2))\n",
    "        env.predator_density = y0[:,:,0]\n",
    "        env.prey_density = prey_data\n",
    "        # initialize trap locations based on predictions\n",
    "        trap_locations = predict(env, agent)\n",
    "        for i,j in trap_locations:\n",
    "            y0[i, j, 1] = 10\n",
    "        y0 = y0.flatten()\n",
    "        for _ in range(replacement_window):\n",
    "            # trap solver, only grab single timestep\n",
    "            sol = solve_ivp(synthetic_data.spatial_dynamics_traps, y0=y0, t_span=[0,1], t_eval=np.linspace(0, 1, pts_per_sec), args=(n, m))\n",
    "            # prey solver y0 creation\n",
    "            y_prey = np.zeros((n, m, 2))\n",
    "            last_dim = int(pts_per_sec)\n",
    "            sol_use = sol.y.reshape((n, m, 2, last_dim))\n",
    "            pred_data_new, trap_data_new = sol_use[:, :, 0, :], sol_use[:, :, 1, :]\n",
    "            # set prey from timestep of interest as predator in y_prey\n",
    "            y_prey[:,:,1] = pred_data_new[:, :, -1]\n",
    "            # grab predator information from prey data\n",
    "            y_prey[:,:,0] = prey_data\n",
    "            y_prey = y_prey.flatten()\n",
    "            # prey solver, only grab single timestep\n",
    "            sol_prey = solve_ivp(synthetic_data.spatial_dynamics, y0=y_prey, t_span=[0,1], t_eval=np.linspace(0, 1, pts_per_sec), args=(n, m))\n",
    "            # create y0 for next run of trap solver, overwrite y0 and prey_data\n",
    "            y0 = np.zeros((n, m, 2))\n",
    "            sol_prey_use = sol_prey.y.reshape((n, m, 2, last_dim))\n",
    "            prey_data, predator_data = sol_prey_use[:, :, 0, :], sol_prey_use[:, :, 1, :]\n",
    "            y0[:,:,0] = predator_data[:, :, -1]\n",
    "            prey_data = prey_data[:, :, -1]\n",
    "            # initialize trap locations based on number of desired traps and density, re initialize per replacement time\n",
    "            y0[:,:,1] = trap_data_new[:,:,-1]\n",
    "            y0 = y0.flatten()\n",
    "            master_sol = np.concatenate((master_sol, sol_prey.y), 1)\n",
    "\n",
    "    # save master sol object\n",
    "    print(master_sol[:,100:].shape)\n",
    "    np.save(save_loc, master_sol[:,100:])\n",
    "\n",
    "\n",
    "def plot_predator_locations_at_timestep_here(file_loc, timestep):\n",
    "    dataset = np.load(file_loc)\n",
    "    data = dataset.reshape((25, 25, 2, 5000))\n",
    "    plot_predator_locations_here(data, timestep*100)\n",
    "\n",
    "def plot_predator_locations_here(grid, timestep):\n",
    "    #Get the min and max of all your data\n",
    "    _min, _max = np.amin(grid), np.amax(grid)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(2, 1, 1)\n",
    "    #Add the vmin and vmax arguments to set the color scale\n",
    "    ax.imshow(grid[:, :, 0, timestep], cmap=plt.cm.YlGn, vmin = _min, vmax = _max)\n",
    "    ax2 = fig.add_subplot(2, 1, 2)\n",
    "    #Add the vmin and vmax arguments to set the color scale\n",
    "    ax2.imshow(grid[:, :, 1, timestep], cmap=plt.cm.YlGn, vmin = _min, vmax = _max)\n",
    "    plt.show()\n",
    "\n",
    "generate_traps_next(env,trap_locations)\n",
    "\n",
    "# Create an interactive slider\n",
    "interact(plot_predator_locations_at_timestep_here, file_loc='../Data/val_predict.npy', timestep=IntSlider(min=0, max=max_timestep, step=1, value=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save to file\n",
    "with open('variable.pkl', 'wb') as f:\n",
    "    pickle.dump(agent, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from file\n",
    "with open('variable.pkl', 'rb') as f:\n",
    "    new_agent = pickle.load(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "365bf65fb91c106cdbd1c0bc03ff0be5109c6b4cf462d087395592db3f17fbb1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
